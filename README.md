# Llama4-maverick-17B â€“ Dataset creator Backend

**Repository:** `llama-dataset`

This repository contains the **backend API** for collecting and managing high-quality agricultural Q&A datasets used to fine-tune **LLaMA-4 Maverick 17B** with **LoRA** for **Farm Vaidya AI**.

The system is designed to be **secure, scalable, intern-safe, and research-grade**, with clean **JSONL datasets stored in AWS S3**.

---

## ğŸš€ Project Overview

**Farm Vaidya AI** is an AI assistant for Indian farmers (AP & Telangana), providing:

* Crop-specific agricultural guidance
* Multilingual support (Telugu / Hindi / English)
* Behavior-controlled responses (theory, practice, diagnostics, etc.)

This backend enables **structured data collection** via a web UI and safely stores it for model training.

---

## ğŸ§  Core Design Principles

* âœ… **JSONL contains ONLY userâ€“assistant pairs**
* âœ… **System prompts are NOT stored in JSONL**
* âœ… System prompts are injected **at training time**
* âœ… Append-only dataset (no accidental deletion)
* âœ… UTF-8 safe (Indian languages supported)
* âœ… Secure AWS IAM access (programmatic only)

---

## ğŸ“ Backend Folder Structure

```
llama-dataset/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ s3_client.py
â”‚   â”‚   â””â”€â”€ validators.py
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ submission.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ s3_service.py
â”‚   â”‚   â””â”€â”€ logging_service.py
â”‚   â”‚
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ railway.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ”§ Tech Stack

* **Backend Framework:** FastAPI
* **Cloud Storage:** AWS S3
* **Deployment:** Railway
* **Frontend:** Vercel (separate repo)
* **Language:** Python 3.10+

---

## ğŸ“¦ API Endpoints

### Health Check

```
GET /
```

Response:

```json
{ "status": "ok" }
```

---

### List Behaviors

```
GET /behaviors
```

Returns:

```json
[
  "theoretical",
  "practical",
  "calculation",
  "diagnostic",
  "preventive",
  "safety"
]
```

---

### Submit Dataset Entries

```
POST /submit
```

#### Request Body

```json
{
  "crop": "Rice",
  "behavior": "theoretical",
  "qa_pairs": [
    {
      "question": "à°¬à°¿à°¯à±à°¯à°‚ à°ªà°‚à°Ÿà°•à± à°¯à±‚à°°à°¿à°¯à°¾ à°à°‚à°¤ à°µà±‡à°¯à°¾à°²à°¿?",
      "answer": "à°à°•à°°à°¾à°•à± 45â€“50 à°•à°¿à°²à±‹à°² à°¯à±‚à°°à°¿à°¯à°¾ à°°à±†à°‚à°¡à± à°µà°¿à°¡à°¤à°²à°²à±‹ à°µà±‡à°¯à°¾à°²à°¿."
    }
  ],
  "submitted_by": "intern_name"
}
```

#### Response

```json
{
  "status": "success",
  "inserted": 1
}
```

---

## ğŸª£ AWS S3 Structure

```
s3://llama4mav-dataset/
â”‚
â”œâ”€â”€ Rice/
â”‚   â”œâ”€â”€ Rice_systemprompt_theoretical.txt
â”‚   â”œâ”€â”€ Rice_theoretical.jsonl
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ metadata/
    â””â”€â”€ logs/
        â””â”€â”€ submissions.jsonl
```

* ğŸ“Œ System prompts â†’ **read-only**
* ğŸ“Œ JSONL files â†’ **append-only**

---

## ğŸ” Environment Variables (Railway)

Set these in **Railway â†’ Variables**:

```env
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
AWS_REGION=ap-south-1
S3_BUCKET_NAME=llama4mav-dataset
```

âš ï¸ **Never commit `.env` to GitHub**

---

## ğŸ§ª Local Development

Install dependencies:

```bash
pip install -r requirements.txt
```

Run server:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Swagger UI:

```
http://localhost:8000/docs
```

---

## ğŸš€ Deployment

* Backend is deployed via **Railway (GitHub integration)**
* Every push to `main` triggers auto-deployment
* Frontend (Vercel) communicates via public Railway URL

---
